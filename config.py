# config.py
KNOWLEDGE_BASE_DIR = "./knowledge_base/"
# EMBEDDING_MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"
EMBEDDING_MODEL_NAME = "mixedbread-ai/mxbai-embed-large-v1"
GROQ_MODEL_ID = "llama-3.1-8b-instant"
WHISPER_MODEL_NAME = "base"
TTS_VOICE_DIR = "./tts_voice/"
SPEAKER_VOICE_DIR = "./speaker_voice/"
# GROQ_WHISPER_MODEL_ID = "whisper-large-v3"
GROQ_WHISPER_MODEL_ID = "mixtral-8x7b-32768"
# WHISPER_MODEL_NAME = "medium"
# New configuration for our cloud-based TTS
ELEVENLABS_VOICE_ID = "21m00Tcm4TlvDq8ikWAM" # This is the ID for the voice 'Rachel'
LLAMA_GUARD_MODEL_ID = "meta-llama/llama-guard-4-12b"
TTS_MODEL_NAME = "tts_models/multilingual/multi-dataset/xtts_v2"
